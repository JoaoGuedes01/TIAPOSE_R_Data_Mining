install.packages("rminer")
x=1
x+2
print(ola)
print("ola")
a="hello"
v=0.02
b=0.02
c=-2
d=2^3
e=2.2e-1
is
is()
Is()
print(a)
ls()
plot()
d
e
x=c(1.1,2.3,-1,4,2e-2)
x
x[2]
x
x[0]
x[1]
x[3]
x[2] =0
x[2]
x
clear
cl
cls
summary(x)
x+1
length(x)
x[length(x)]=10; print(x)
z=vector(length = 5)
print(z)
z[]=1
z
z[c(1,3,5)]=2;print(z)
sum(z)
plot(z,type = "b", lwd=2, col="blue")
plot(z,type = "a", lwd=2, col="blue")
plot(z,type = "b", lwd=2, col="blue")
help()
a[1:3];print(a)
a=rep(3,10);print(a)
a[1:3];print(a)
a[1:5];print(a)
a[1:5]=1;print(a)
seq(1,3,2)
seq(1,3,2)
f=seq(1,3,2)
f[1:5]=1
f
f[6:10]=3
f
seq(1,3,[1:5]=1)
seq(1,3,2), each = 5;
seq(1,3,2) + each = 5;
rep(seq(1,3,2) , each = 5)
rep(seq(1,3,2),5)
library(rminer) # powerful rminer
library(rpart.plot) # plot nice decision trees
library(tictoc) # timer
# classification demo, using wine quality from UCI:
path="https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/"
file=paste(path,"winequality-white.csv",sep="")
w=read.table(file,sep=";",header=TRUE)
w$quality=cut(w$quality,c(0,5.5,6.5,10),c("bad","medium","good"))
# save transformed data into a new csv: wq3.csv (bad,medium,good):"
write.table(file="wq3.csv",w,row.names=FALSE,col.names=TRUE,sep=";")
# simple time ordered holdout split
H=holdout(w$quality,ratio=2/3,mode="order")
cat("fit a decision tree:\n")
tic()
dt=fit(quality~.,w[H$tr,],model="dt")
toc()
# show decision tree:
rpart.plot(dt@object)
# fit a SVM with no hyperparameter tuning:
cat("fit a SVM:\n")
tic()
svm=fit(quality~.,w[H$tr,],model="ksvm")
toc()
# show main svm model:
print(svm@object)
# fit a SVM with some hyperparameter tuning:
# training data is further divided into fit (2/3) and validation sets (1/3)
# "UD" - is a special uniform design with 13 searches for the Gaussian SVM hyperparameters (C and sigma)
cat("fit SVM2 (uniform design search):\n")
tic()
s=list(search=mparheuristic("ksvm",5),method=c("holdoutorder",2/3))
svm2=fit(quality~.,w[H$tr,],model="ksvm",search=s)
toc()
print(svm2@object)
# analysis of the quality of the predictions on the test set:
pdt=predict(dt,w[H$ts,])
psvm=predict(svm,w[H$ts,])
psvm2=predict(svm2,w[H$ts,])
Y=w[H$ts,]$quality # target output variable
print("classification metrics:")
cat("class. metrics for dt:")
print(mmetric(Y,pdt,metric=c("ACC","AUC","macroF1","ACCLASS","AUCCLASS","F1")))
cat("class. metrics for svm:")
print(mmetric(Y,psvm,metric=c("ACC","AUC","macroF1","ACCLASS","AUCCLASS","F1")))
cat("class. metrics for svm2:")
print(mmetric(Y,psvm2,metric=c("ACC","AUC","macroF1","ACCLASS","AUCCLASS","F1")))
# examples of confusion matrices:
print("dt confusion matrix:")
print(mmetric(Y,pdt,metric="CONF")$conf)
print("dt confusion matrix for class good:")
print(mmetric(Y,pdt,TC=3,metric="CONF")$conf)
print("dt confusion matrix for class good and D=0.7:") # more specific model
print(mmetric(Y,pdt,TC=3,D=0.6,metric="CONF")$conf)
print("dt confusion matrix for class good and D=0.3:") # more sensitive model
print(mmetric(Y,pdt,TC=3,D=0.3,metric="CONF")$conf)
# ROC curves:
# simple ROC curve for svm target class good (TC=3):
mgraph(Y,psvm,graph="ROC",TC=3,baseline=TRUE,leg="Good",Grid=10)
# more elaborated ROC curve:
L=vector("list",3) # needed because of mgraph multi ROC plot
testl=vector("list",1);testl[[1]]=Y # same TEST target for all 3 models
p1=vector("list",1);p1[[1]]=pdt
p2=vector("list",1);p2[[1]]=psvm
p3=vector("list",1);p3[[1]]=psvm2
L[[1]]=list(pred=p1,test=testl,runs=1)
L[[2]]=list(pred=p2,test=testl,runs=1)
L[[3]]=list(pred=p3,test=testl,runs=1)
auc1=round(mmetric(Y,pdt,metric="AUC",TC=3),digits=2)
auc2=round(mmetric(Y,psvm,metric="AUC",TC=3),digits=2)
auc3=round(mmetric(Y,psvm2,metric="AUC",TC=3),digits=2)
leg=c(paste("dt (AUC=",auc1,")",sep=""),paste("svm (AUC=",auc2,")",sep=""),paste("svm2 (AUC=",auc3,")",sep=""))
mgraph(L,graph="ROC",TC=3,baseline=TRUE,leg=list(pos="bottomright",leg=leg),main="ROC for Good",Grid=10)
# LIFT curves (useful for marketing tasks):
# simple LIFT curve for svm target class good (TC=3):
mgraph(Y,psvm,graph="LIFT",TC=3,baseline=TRUE,leg="Good",Grid=10)
# more elaborated LIFT curve:
# in this example, a new pdf file is created:
pdf("wine-lift.pdf",width=5,height=5) # diverts graph to PDF
L=vector("list",3) # needed because of mgraph multi ROC plot
testl=vector("list",1);testl[[1]]=Y # same TEST target for all 3 models
p1=vector("list",1);p1[[1]]=pdt
p2=vector("list",1);p2[[1]]=psvm
p3=vector("list",1);p3[[1]]=psvm2
L[[1]]=list(pred=p1,test=testl,runs=1)
L[[2]]=list(pred=p2,test=testl,runs=1)
L[[3]]=list(pred=p3,test=testl,runs=1)
auc1=round(mmetric(Y,pdt,metric="ALIFT",TC=3),digits=2)
auc2=round(mmetric(Y,psvm,metric="ALIFT",TC=3),digits=2)
auc3=round(mmetric(Y,psvm2,metric="ALIFT",TC=3),digits=2)
leg=c(paste("dt (ALIFT=",auc1,")",sep=""),paste("svm (ALIFT=",auc2,")",sep=""),paste("svm2 (ALIFT=",auc3,")",sep=""))
mgraph(L,graph="LIFT",TC=3,baseline=TRUE,leg=list(pos=c(0.4,0.3),leg=leg),main="LIFT for Good",Grid=10)
dev.off() # closes PDF
# "Read the automobile data:"
d=read.table("imports-85.csv",sep=",",header=TRUE,na.strings="?",stringsAsFactors=TRUE)
print(summary(d))
# "Read the automobile data:"
d=read.table("imports-85.csv",sep=",",header=TRUE,na.strings="?",stringsAsFactors=TRUE)
# "Read the automobile data:"
d=read.table("imports-85.csv",sep=",",header=TRUE,na.strings="?",stringsAsFactors=TRUE)
home
home()
library(rminer)
setwd("D:/PC/UM/4_ano/2_Semestre/TIAPOSE/semana4/teste")
